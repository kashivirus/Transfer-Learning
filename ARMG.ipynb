{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ARMG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoqPk0fNfGXm"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model,load_model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "\n",
        "test_dir = '/content/drive/MyDrive/KASHIF DEEP LEARNING/transfer learning/ Jason Brownlee/dataBase/test'\n",
        "\n",
        "validation_dir = '/content/drive/MyDrive/KASHIF DEEP LEARNING/transfer learning/ Jason Brownlee/dataBase/val'\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/KASHIF DEEP LEARNING/transfer learning/ Jason Brownlee/dataBase/train'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVeuw2dEfMGx"
      },
      "source": [
        "image_size=[263,173]\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVYYtu5OfNCp"
      },
      "source": [
        "def dataset(train_path,test_path):\n",
        "    datagen = ImageDataGenerator()\n",
        "    train_set = datagen.flow_from_directory(train_path, class_mode='categorical', batch_size=20,target_size=image_size)\n",
        "    test_set = datagen.flow_from_directory(test_path, class_mode='categorical', batch_size=20,target_size=image_size)\n",
        "    return train_set,test_set"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql0qZkKJfOy7"
      },
      "source": [
        "def model_creation(model_name):\n",
        "    \n",
        "    vgg_model = model_name(weights='imagenet', include_top=False, input_shape=image_size + [3])\n",
        "    \n",
        "    for layer in vgg_model.layers:\n",
        "        layer.trainable=False    \n",
        "\n",
        "\n",
        "\n",
        "    xx=Dropout(rate=0.20)(vgg_model.output)\n",
        "    x=Flatten()(xx)\n",
        "    prediction=Dense(12,activation=\"softmax\")(x)\n",
        "    model=Model(inputs=vgg_model.input , outputs=prediction)\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo08oJSs04_e"
      },
      "source": [
        "\n",
        "# for layer in model.layers:\n",
        "#     print(layer, layer.trainable)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ifPVn-NfSCL",
        "outputId": "71f228df-5c8e-4fbc-a450-8e534ab9452c"
      },
      "source": [
        "\n",
        "model=model_creation(VGG16)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 263, 173, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 263, 173, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 263, 173, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 131, 86, 64)       0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 131, 86, 128)      73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 131, 86, 128)      147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 65, 43, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 65, 43, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 65, 43, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 65, 43, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 21, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 21, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 21, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 21, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 16, 10, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 16, 10, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 16, 10, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 16, 10, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 8, 5, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8, 5, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 20480)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 12)                245772    \n",
            "=================================================================\n",
            "Total params: 14,960,460\n",
            "Trainable params: 245,772\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR2lDD0ttuPh",
        "outputId": "b2aac200-b999-4086-8e21-249cc7b7369f"
      },
      "source": [
        "\n",
        "for layer in model.layers:\n",
        "    print(layer, layer.trainable)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7f018c65a050> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f012a652290> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f012a679f50> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f0129dbfb50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f0120529b50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f0120531f50> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f0120533a10> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f0120538950> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f01205418d0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f0120533cd0> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f0120549310> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f01204ce4d0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f018913b650> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f01204d62d0> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f01204e0350> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f01204dbf50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f0120549490> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f01204ec2d0> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f01204f1d90> False\n",
            "<keras.layers.core.Dropout object at 0x7f0120545390> True\n",
            "<keras.layers.core.Flatten object at 0x7f01204e4750> True\n",
            "<keras.layers.core.Dense object at 0x7f01204ff8d0> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCCpOPcXfUDn",
        "outputId": "081ecf39-78eb-4d67-bbdd-464987de950d"
      },
      "source": [
        "train=train_dir\n",
        "test=validation_dir\n",
        "train_set,test_set=dataset(train,test)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4200 images belonging to 12 classes.\n",
            "Found 1200 images belonging to 12 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_201QUMESLM"
      },
      "source": [
        "import tensorflow as tf\n",
        "# filepath = '/content/drive/MyDrive/KASHIF DEEP LEARNING/transfer learning/ Jason Brownlee/dataBase/George zoto   97/temp_saved'\n",
        "filepath  = '/content/drive/MyDrive/KASHIF DEEP LEARNING/transfer learning/ Jason Brownlee/dataBase/here'\n",
        "\n",
        "\n",
        "\n",
        "checkpoint_filepath = '/content/drive/MyDrive/KASHIF DEEP LEARNING/transfer learning/ Jason Brownlee/dataBase/here/check.h5'\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    verbose = 1,\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# call = tf.keras.callbacks.ModelCheckpoint(\n",
        "#     filepath,\n",
        "#     monitor=\"val_loss\",\n",
        "#     verbose=0,\n",
        "#     save_best_only=True,\n",
        "#     save_weights_only=False,\n",
        "#     mode=\"auto\",\n",
        "#     save_freq=\"epoch\",\n",
        "#     options=None,\n",
        "# )\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXITkb7Budjx"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'] ,)\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHK2DdXo9wJ7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALYP_qYhtNUj",
        "outputId": "00a77a86-15b1-4ca0-da04-b7c8e6b211e8"
      },
      "source": [
        "# from keras.optimizers import SGD\n",
        "# tf.keras.optimizers.SGD(\n",
        "#     learning_rate=0.01, momentum=0.0, nesterov=False, name=\"SGD\", **kwargs\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "# from keras.optimizers import sgd\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True) ,\n",
        "              metrics=['accuracy'] ,)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOw0DPurgg0I",
        "outputId": "3132ec46-2dc9-4ae1-e6b2-a39c0753b592"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "history=model.fit(train_set,\n",
        "                  validation_data=test_set,\n",
        "                  epochs=5,\n",
        "                 callbacks = [model_checkpoint_callback , callback],\n",
        "                  shuffle=True ,\n",
        "                )"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "210/210 [==============================] - 1254s 6s/step - loss: 97.5781 - accuracy: 0.8281 - val_loss: 27.8889 - val_accuracy: 0.9317\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.93167, saving model to /content/drive/MyDrive/KASHIF DEEP LEARNING/transfer learning/ Jason Brownlee/dataBase/here/check.h5\n",
            "Epoch 2/5\n",
            "210/210 [==============================] - 56s 265ms/step - loss: 27.3282 - accuracy: 0.9419 - val_loss: 22.7960 - val_accuracy: 0.9475\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.93167 to 0.94750, saving model to /content/drive/MyDrive/KASHIF DEEP LEARNING/transfer learning/ Jason Brownlee/dataBase/here/check.h5\n",
            "Epoch 3/5\n",
            "210/210 [==============================] - 56s 267ms/step - loss: 17.4216 - accuracy: 0.9614 - val_loss: 32.3361 - val_accuracy: 0.9417\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.94750\n",
            "Epoch 4/5\n",
            "210/210 [==============================] - 56s 266ms/step - loss: 10.9039 - accuracy: 0.9760 - val_loss: 10.5860 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.94750 to 0.97583, saving model to /content/drive/MyDrive/KASHIF DEEP LEARNING/transfer learning/ Jason Brownlee/dataBase/here/check.h5\n",
            "Epoch 5/5\n",
            "210/210 [==============================] - 56s 266ms/step - loss: 6.0595 - accuracy: 0.9821 - val_loss: 10.9672 - val_accuracy: 0.9733\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.97583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCOZAvl-wsPw",
        "outputId": "fb6567fa-1dd0-47c4-9d15-564351eaf8fa"
      },
      "source": [
        "model.save('/content/drive/MyDrive/KASHIF DEEP LEARNING/transfer learning/ Jason Brownlee/dataBase/George 97.33')   "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/KASHIF DEEP LEARNING/transfer learning/ Jason Brownlee/dataBase/George 97.33/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpc-yRGN5bu-"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "vgg16_saved = load_model('/content/drive/MyDrive/KASHIF DEEP LEARNING/transfer learning/ Jason Brownlee/dataBase/George 97.33')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xleUNhCxbFZ",
        "outputId": "4374b8f8-55df-4cb5-df25-f77406750dbc"
      },
      "source": [
        "\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "test_generator =  test_datagen.flow_from_directory( test_dir,\n",
        "                                                          batch_size  = 32,\n",
        "                                                          class_mode  = 'categorical', \n",
        "                                                          target_size = image_size)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 600 images belonging to 12 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02LzpW2txeo6",
        "outputId": "d07457e4-aa18-481b-d179-67a694ea3402"
      },
      "source": [
        "predict_vgg16  =vgg16_saved.evaluate(test_generator, \n",
        "                                    batch_size=None,\n",
        "                                    verbose=1, \n",
        "                                    steps=600/32,\n",
        "                                    callbacks=None,\n",
        "                                    max_queue_size=10, \n",
        "                                    workers=1, use_multiprocessing=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 131s 7s/step - loss: 14.2695 - accuracy: 0.6350\n"
          ]
        }
      ]
    }
  ]
}